{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUIxw7JH5zjN"
   },
   "source": [
    "# HPO: Hyper-parameter Optimization\n",
    "\n",
    "[HPO Method]\n",
    "1. Grid Search\n",
    "2. Random Search\n",
    "3. Bayesian Search\n",
    "4. Bayesian Search(TPE:Tree-structured Parzen Estimator) using Optuna\n",
    "\n",
    "[Data]  \n",
    "Bank Marketing Data set  \n",
    "https://archive.ics.uci.edu/dataset/222/bank+marketing\n",
    "\n",
    "[Note]  \n",
    "HPO Example로 오류방지를 위한 최소한의 전처리만 수행\n",
    "\n",
    "\n",
    "[Task 1]  \n",
    "위 예시 사례를 활용하고 적용모델을 달리하여 하이퍼 파라메타 최적화(HPO)를 수행해보세요  \n",
    " - HPO Method 중 2개의 Method를 선정하여 비교분석 해보세요.\n",
    " - 적용 모델을 다르게.. (XGBoost 제외)\n",
    "  \n",
    "   \n",
    "[Task 2]  \n",
    "하기 데이터를 활용하여 하이퍼 파라메타 최적화(HPO)를 수행해보세요  \n",
    " - HPO Method 중 2개의 Method를 선정하여 비교분석 해보세요.\n",
    " - 모델선택은 자유  \n",
    "  \n",
    "활용 데이터 : Adult(Census Income)(2)    \n",
    "https://archive.ics.uci.edu/dataset/2/adult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zG-UBFlWUkXW",
    "outputId": "bcda0b89-e298-48c5-f386-881f886953bd"
   },
   "outputs": [],
   "source": [
    "#  UCI Machine Learning Data Load Library\n",
    "# !pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0aAdfp5EK6h",
    "outputId": "d184233f-8cba-4c89-b84f-550d46cd8ad5"
   },
   "outputs": [],
   "source": [
    "#  Bayesian Search Library\n",
    "# !pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrxkrMJPkhWy",
    "outputId": "b76f58e8-3697-4a4a-de8f-fc5c1e9c3659"
   },
   "outputs": [],
   "source": [
    "#  Bayesian Search(TPE) Library\n",
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-qBOXEYidoeE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, LeaveOneOut\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "import time\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gnco0b6RHDiC"
   },
   "source": [
    "## 1. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hiWV7xdtcXsy",
    "outputId": "e0e42375-5fc8-4458-f892-00ec29108328"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45211, 17)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   age          45211 non-null  int64 \n",
      " 1   job          44923 non-null  object\n",
      " 2   marital      45211 non-null  object\n",
      " 3   education    43354 non-null  object\n",
      " 4   default      45211 non-null  object\n",
      " 5   balance      45211 non-null  int64 \n",
      " 6   housing      45211 non-null  object\n",
      " 7   loan         45211 non-null  object\n",
      " 8   contact      32191 non-null  object\n",
      " 9   day_of_week  45211 non-null  int64 \n",
      " 10  month        45211 non-null  object\n",
      " 11  duration     45211 non-null  int64 \n",
      " 12  campaign     45211 non-null  int64 \n",
      " 13  pdays        45211 non-null  int64 \n",
      " 14  previous     45211 non-null  int64 \n",
      " 15  poutcome     8252 non-null   object\n",
      " 16  y            45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n",
      "Info: None\n",
      "Samples:    age           job  marital  education default  balance housing loan  \\\n",
      "0   58    management  married   tertiary      no     2143     yes   no   \n",
      "1   44    technician   single  secondary      no       29     yes   no   \n",
      "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
      "3   47   blue-collar  married        NaN      no     1506     yes   no   \n",
      "4   33           NaN   single        NaN      no        1      no   no   \n",
      "\n",
      "  contact  day_of_week month  duration  campaign  pdays  previous poutcome   y  \n",
      "0     NaN            5   may       261         1     -1         0      NaN  no  \n",
      "1     NaN            5   may       151         1     -1         0      NaN  no  \n",
      "2     NaN            5   may        76         1     -1         0      NaN  no  \n",
      "3     NaN            5   may        92         1     -1         0      NaN  no  \n",
      "4     NaN            5   may       198         1     -1         0      NaN  no  \n",
      "Bank Marketing Dataset load\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "def load_data():\n",
    "\n",
    "    # fetch dataset\n",
    "    bank_marketing = fetch_ucirepo(id=222)\n",
    "\n",
    "    # data (as pandas dataframes)\n",
    "    X = bank_marketing.data.features\n",
    "    y = bank_marketing.data.targets\n",
    "\n",
    "    # Concatenate\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Info: {df.info()}\")\n",
    "    print(f\"Samples: {df.head(5)}\")\n",
    "    print(\"Bank Marketing Dataset load\")\n",
    "\n",
    "    return df, X, y\n",
    "\n",
    "# 1.데이터 로드\n",
    "df, X, y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_94l-KdhHK98"
   },
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRR3tIPD3kV-",
    "outputId": "f1e95bf9-7e79-4c17-f79e-e2ef105c7c51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 타입:\n",
      "age             int64\n",
      "job            object\n",
      "marital        object\n",
      "education      object\n",
      "default        object\n",
      "balance         int64\n",
      "housing        object\n",
      "loan           object\n",
      "contact        object\n",
      "day_of_week     int64\n",
      "month          object\n",
      "duration        int64\n",
      "campaign        int64\n",
      "pdays           int64\n",
      "previous        int64\n",
      "poutcome       object\n",
      "y              object\n",
      "dtype: object\n",
      "\n",
      "결측치 확인:\n",
      "age                0\n",
      "job              288\n",
      "marital            0\n",
      "education       1857\n",
      "default            0\n",
      "balance            0\n",
      "housing            0\n",
      "loan               0\n",
      "contact        13020\n",
      "day_of_week        0\n",
      "month              0\n",
      "duration           0\n",
      "campaign           0\n",
      "pdays              0\n",
      "previous           0\n",
      "poutcome       36959\n",
      "y                  0\n",
      "dtype: int64\n",
      "\n",
      "타겟 변수 분포:\n",
      "y\n",
      "no     39922\n",
      "yes     5289\n",
      "Name: count, dtype: int64\n",
      "비율: y\n",
      "no     88.30152\n",
      "yes    11.69848\n",
      "Name: count, dtype: float64\n",
      "\n",
      "숫자형 변수 기본 통계:\n",
      "                age        balance   day_of_week      duration      campaign  \\\n",
      "count  45211.000000   45211.000000  45211.000000  45211.000000  45211.000000   \n",
      "mean      40.936210    1362.272058     15.806419    258.163080      2.763841   \n",
      "std       10.618762    3044.765829      8.322476    257.527812      3.098021   \n",
      "min       18.000000   -8019.000000      1.000000      0.000000      1.000000   \n",
      "25%       33.000000      72.000000      8.000000    103.000000      1.000000   \n",
      "50%       39.000000     448.000000     16.000000    180.000000      2.000000   \n",
      "75%       48.000000    1428.000000     21.000000    319.000000      3.000000   \n",
      "max       95.000000  102127.000000     31.000000   4918.000000     63.000000   \n",
      "\n",
      "              pdays      previous  \n",
      "count  45211.000000  45211.000000  \n",
      "mean      40.197828      0.580323  \n",
      "std      100.128746      2.303441  \n",
      "min       -1.000000      0.000000  \n",
      "25%       -1.000000      0.000000  \n",
      "50%       -1.000000      0.000000  \n",
      "75%       -1.000000      0.000000  \n",
      "max      871.000000    275.000000  \n",
      "\n",
      "범주형 변수 고유값 개수:\n",
      "job: 11개 고유값\n",
      "\n",
      "marital: 3개 고유값\n",
      "marital\n",
      "married     27214\n",
      "single      12790\n",
      "divorced     5207\n",
      "Name: count, dtype: int64\n",
      "\n",
      "education: 3개 고유값\n",
      "education\n",
      "secondary    23202\n",
      "tertiary     13301\n",
      "primary       6851\n",
      "Name: count, dtype: int64\n",
      "\n",
      "default: 2개 고유값\n",
      "default\n",
      "no     44396\n",
      "yes      815\n",
      "Name: count, dtype: int64\n",
      "\n",
      "housing: 2개 고유값\n",
      "housing\n",
      "yes    25130\n",
      "no     20081\n",
      "Name: count, dtype: int64\n",
      "\n",
      "loan: 2개 고유값\n",
      "loan\n",
      "no     37967\n",
      "yes     7244\n",
      "Name: count, dtype: int64\n",
      "\n",
      "contact: 2개 고유값\n",
      "contact\n",
      "cellular     29285\n",
      "telephone     2906\n",
      "Name: count, dtype: int64\n",
      "\n",
      "month: 12개 고유값\n",
      "\n",
      "poutcome: 3개 고유값\n",
      "poutcome\n",
      "failure    4901\n",
      "other      1840\n",
      "success    1511\n",
      "Name: count, dtype: int64\n",
      "\n",
      "y: 2개 고유값\n",
      "y\n",
      "no     39922\n",
      "yes     5289\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def eda_data(df):\n",
    "\n",
    "    # 기본 통계\n",
    "    print(\"데이터 타입:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print(\"\\n결측치 확인:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    print(\"\\n타겟 변수 분포:\")\n",
    "    target_counts = df['y'].value_counts()\n",
    "    print(target_counts)\n",
    "    print(f\"비율: {target_counts / len(df) * 100}\")\n",
    "\n",
    "    print(\"\\n숫자형 변수 기본 통계:\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    print(df[numeric_cols].describe())\n",
    "\n",
    "    print(\"\\n범주형 변수 고유값 개수:\")\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        print(f\"{col}: {df[col].nunique()}개 고유값\")\n",
    "        if df[col].nunique() <= 10:  # 고유값이 적으면 분포 출력\n",
    "            print(df[col].value_counts().head())\n",
    "        print()\n",
    "\n",
    "# 2.데이터 탐색\n",
    "eda_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oah4BY4nHR_4"
   },
   "source": [
    "## 3. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjnAjdPMeVDA",
    "outputId": "036cfccc-eb75-4fe2-b378-2fa2ead9a639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job 인코딩 완료: 12개 클래스\n",
      "marital 인코딩 완료: 3개 클래스\n",
      "education 인코딩 완료: 4개 클래스\n",
      "default 인코딩 완료: 2개 클래스\n",
      "housing 인코딩 완료: 2개 클래스\n",
      "loan 인코딩 완료: 2개 클래스\n",
      "contact 인코딩 완료: 3개 클래스\n",
      "month 인코딩 완료: 12개 클래스\n",
      "poutcome 인코딩 완료: 4개 클래스\n",
      "타겟 분포: {0: 39922, 1: 5289}\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(X, y):\n",
    "\n",
    "    # 데이터프레임 복사\n",
    "    X_processed = X.copy()\n",
    "\n",
    "    # 범주형 변수들을 레이블 인코딩\n",
    "    categorical_columns = X_processed.select_dtypes(include=['object']).columns\n",
    "    label_encoders = {}\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        X_processed[col] = le.fit_transform(X_processed[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "        print(f\"{col} 인코딩 완료: {len(le.classes_)}개 클래스\")\n",
    "\n",
    "    # 타겟 변수 인코딩 (yes=1, no=0)\n",
    "    y_processed = (y['y'] == 'yes').astype(int)\n",
    "\n",
    "    print(f\"타겟 분포: {y_processed.value_counts().to_dict()}\")\n",
    "\n",
    "    return X_processed, y_processed, label_encoders\n",
    "\n",
    "\n",
    "# 3. 데이터 전처리\n",
    "X_processed, y_processed, label_encoders = preprocess_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y40RAY6nm7A8",
    "outputId": "b59eee8e-3b53-4ce5-b0f6-875d1cb52686"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job': LabelEncoder(),\n",
       " 'marital': LabelEncoder(),\n",
       " 'education': LabelEncoder(),\n",
       " 'default': LabelEncoder(),\n",
       " 'housing': LabelEncoder(),\n",
       " 'loan': LabelEncoder(),\n",
       " 'contact': LabelEncoder(),\n",
       " 'month': LabelEncoder(),\n",
       " 'poutcome': LabelEncoder()}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVEDBtwlHYfl"
   },
   "source": [
    "## 4. Baseline Modeling & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRB9XN1EfdIR",
    "outputId": "fa29f63e-a811-4294-894b-cad9507f5b2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoost 모델 구축 및 평가 ===\n",
      "훈련 데이터: (36168, 16)\n",
      "테스트 데이터: (9043, 16)\n",
      "XGBoost Learning...\n",
      "\n",
      "정확도: 0.9103\n",
      "AUC 점수: 0.9314\n",
      "\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      7985\n",
      "           1       0.67      0.45      0.54      1058\n",
      "\n",
      "    accuracy                           0.91      9043\n",
      "   macro avg       0.80      0.71      0.75      9043\n",
      "weighted avg       0.90      0.91      0.90      9043\n",
      "\n",
      "\n",
      "혼동 행렬:\n",
      "[[7752  233]\n",
      " [ 578  480]]\n",
      "\n",
      "상위 10개 중요한 특성:\n",
      "        feature  importance\n",
      "15     poutcome    0.333886\n",
      "11     duration    0.180560\n",
      "6       housing    0.101092\n",
      "8       contact    0.088195\n",
      "10        month    0.055407\n",
      "7          loan    0.037297\n",
      "13        pdays    0.031768\n",
      "0           age    0.026959\n",
      "12     campaign    0.023817\n",
      "9   day_of_week    0.023566\n"
     ]
    }
   ],
   "source": [
    "def build_and_evaluate_model(X, y):\n",
    "    \"\"\"XGBoost 모델 구축 및 평가\"\"\"\n",
    "    print(\"\\n=== XGBoost 모델 구축 및 평가 ===\")\n",
    "\n",
    "    # 훈련/테스트 데이터 분할\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    print(f\"훈련 데이터: {X_train.shape}\")\n",
    "    print(f\"테스트 데이터: {X_test.shape}\")\n",
    "\n",
    "    # 특성 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # XGBoost 모델 훈련\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        early_stopping_rounds=5,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "\n",
    "    print(\"XGBoost Learning...\")\n",
    "    xgb_model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        eval_set=[(X_test_scaled, y_test)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # 예측\n",
    "    y_pred = xgb_model.predict(X_test_scaled)\n",
    "    y_pred_proba = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # 평가\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    print(f\"\\n정확도: {accuracy:.4f}\")\n",
    "    print(f\"AUC 점수: {auc_score:.4f}\")\n",
    "\n",
    "    print(\"\\n분류 리포트:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"\\n혼동 행렬:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # 특성 중요도\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': xgb_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "    print(\"\\n상위 10개 중요한 특성:\")\n",
    "    print(feature_importance.head(10))\n",
    "\n",
    "    return xgb_model, scaler, feature_importance\n",
    "\n",
    "# 4. 모델 구축 및 평가\n",
    "model, scaler, feature_importance = build_and_evaluate_model(X_processed, y_processed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hzjqybWHtsf"
   },
   "source": [
    "## 5. Cross-Validation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPS8tQFf8YoF",
    "outputId": "91f36ac9-3cbf-414d-f63c-8fc6c13dce7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cross-Validation 전략 비교 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold (5-fold): 0.9330 (±0.0046)\n",
      "StratifiedKFold (5-fold): 0.9333 (±0.0083)\n",
      "StratifiedKFold (20-fold): 0.9341 (±0.0104)\n"
     ]
    }
   ],
   "source": [
    "def compare_cv_strategies(X, y):\n",
    "    \"\"\"다양한 CV 전략 비교\"\"\"\n",
    "    from sklearn.model_selection import KFold, RepeatedStratifiedKFold\n",
    "\n",
    "    print(\"\\n=== Cross-Validation 전략 비교 ===\")\n",
    "\n",
    "    # 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 모델\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "\n",
    "    # CV 전략들\n",
    "    cv_strategies = {\n",
    "    #    'Leave-One-Out (LOOCV)': LeaveOneOut(),\n",
    "        'KFold (5-fold)': KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        'StratifiedKFold (5-fold)': StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        'StratifiedKFold (20-fold)': StratifiedKFold(n_splits=20, shuffle=True, random_state=42)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for name, cv_strategy in cv_strategies.items():\n",
    "        scores = cross_val_score(xgb_model, X_scaled, y, cv=cv_strategy, scoring='roc_auc', n_jobs=-1)\n",
    "        results[name] = {\n",
    "            'mean': scores.mean(),\n",
    "            'std': scores.std(),\n",
    "            'scores': scores\n",
    "        }\n",
    "        print(f\"{name}: {scores.mean():.4f} (±{scores.std()*2:.4f})\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "results = compare_cv_strategies(X_processed, y_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TQg0sQAILtA"
   },
   "source": [
    "## 6-1. HPO: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0leigP098z_",
    "outputId": "76f5a057-9bec-424f-f1f8-2e8b9f6c6e31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 하이퍼파라미터 튜닝 (GridSearchCV) ===\n",
      "GridSearchCV 실행 중...\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "수행 시간: 12.976s\n",
      "최적 파라미터: {'learning_rate': 0.05, 'max_depth': 8, 'n_estimators': 200, 'subsample': 0.8}\n",
      "최적 CV 점수: 0.9350\n"
     ]
    }
   ],
   "source": [
    "def grid_search_tuning_cv(X, y):\n",
    "    \"\"\"Cross-Validation을 활용한 그리드 서치 하이퍼파라미터 튜닝\"\"\"\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    print(\"\\n=== 하이퍼파라미터 튜닝 (GridSearchCV) ===\")\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    # 파라미터 그리드 정의\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [4, 6, 8],\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "\n",
    "    # XGBoost 모델\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "\n",
    "    # GridSearchCV 설정\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=xgb_model,     # 최적화를 적용할 모델\n",
    "        param_grid=param_grid,   # 탐색할 하이퍼파라미터 공간\n",
    "        scoring='roc_auc',\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        n_jobs=-1,               # 병렬 실행 스레드 수, -1 = CPU 전체 사용\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 그리드 서치 실행\n",
    "    print(\"GridSearchCV 실행 중...\")\n",
    "    grid_search.fit(X_scaled, y)\n",
    "\n",
    "    dt = time.perf_counter() - t0\n",
    "    print(f\"수행 시간: {dt:.3f}s\")\n",
    "    print(f\"최적 파라미터: {grid_search.best_params_}\")\n",
    "    print(f\"최적 CV 점수: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "\n",
    "    return grid_search.best_estimator_, scaler\n",
    "\n",
    "\n",
    "best_estimator_, scaler = grid_search_tuning_cv(X_processed, y_processed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgaxmvzyIgse"
   },
   "source": [
    "## 6-2. HPO: Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0fMNWdACAvw",
    "outputId": "62f12e70-4f15-4b68-cdb3-c6e72d724259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 하이퍼파라미터 튜닝 (RandomizedSearchCV) ===\n",
      "RandomizedSearchCV 실행 중...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "수행 시간: 7.856s\n",
      "최적 파라미터: {'subsample': 0.9, 'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "최적 CV 점수: 0.9348\n",
      "\n",
      "상위 5개 파라미터 조합:\n",
      "1. 점수: 0.9348 (±0.0075)\n",
      "   파라미터: {'subsample': 0.9, 'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "2. 점수: 0.9347 (±0.0072)\n",
      "   파라미터: {'subsample': 0.9, 'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.05}\n",
      "3. 점수: 0.9341 (±0.0068)\n",
      "   파라미터: {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "4. 점수: 0.9340 (±0.0085)\n",
      "   파라미터: {'subsample': 1.0, 'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "5. 점수: 0.9340 (±0.0081)\n",
      "   파라미터: {'subsample': 0.9, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "def random_search_tuning(X, y):\n",
    "    \"\"\"Cross-Validation을 활용한 랜덤 서치 하이퍼파라미터 튜닝\"\"\"\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from scipy.stats import uniform, randint\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    print(\"\\n=== 하이퍼파라미터 튜닝 (RandomizedSearchCV) ===\")\n",
    "\n",
    "    # 랜덤 서치를 위한 파라미터 분포 정의\n",
    "    param_distributions = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [4, 6, 8],\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "      #  'colsample_bytree': uniform(0.6, 0.4),\n",
    "    }\n",
    "\n",
    "    # XGBoost 모델\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "\n",
    "    # RandomizedSearchCV 설정\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=xgb_model,      # 최적화를 적용할 모델\n",
    "        param_distributions=param_distributions,  # 탐색할 하이퍼파라미터 분포\n",
    "        n_iter=50,               # 탐색할 반복 횟수\n",
    "        scoring='roc_auc',\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        n_jobs=-1,                # 병렬 실행 스레드 수, -1 = CPU 전체 사용\n",
    "        verbose=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 랜덤 서치 실행\n",
    "    print(\"RandomizedSearchCV 실행 중...\")\n",
    "    random_search.fit(X_scaled, y)\n",
    "\n",
    "    dt = time.perf_counter() - t0\n",
    "    print(f\"수행 시간: {dt:.3f}s\")\n",
    "    print(f\"최적 파라미터: {random_search.best_params_}\")\n",
    "    print(f\"최적 CV 점수: {random_search.best_score_:.4f}\")\n",
    "\n",
    "    # 상위 5개 결과 출력\n",
    "    print(\"\\n상위 5개 파라미터 조합:\")\n",
    "    results_df = pd.DataFrame(random_search.cv_results_)\n",
    "    top_5 = results_df.nlargest(5, 'mean_test_score')[['mean_test_score', 'std_test_score', 'params']]\n",
    "\n",
    "    for idx, (_, row) in enumerate(top_5.iterrows(), 1):\n",
    "        print(f\"{idx}. 점수: {row['mean_test_score']:.4f} (±{row['std_test_score']*2:.4f})\")\n",
    "        print(f\"   파라미터: {row['params']}\")\n",
    "\n",
    "    return random_search.best_estimator_, scaler, random_search\n",
    "\n",
    "best_estimator_, scaler, random_search = random_search_tuning(X_processed, y_processed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOdH5wfxIuoY"
   },
   "source": [
    "## 6-3. HPO: Bayesian Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7O_Qux0_HNG",
    "outputId": "58ced933-7a92-4602-b295-24b3350ca856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 하이퍼파라미터 튜닝 (Bayesian Optimization) ===\n",
      "Bayesian Optimization 실행 중...\n",
      "수행 시간: 26.248s\n",
      "최적 파라미터: OrderedDict([('learning_rate', 0.07064596568969471), ('max_depth', 6), ('n_estimators', 200), ('subsample', 0.8)])\n",
      "최적 CV 점수: 0.9349\n",
      "\n",
      "최적화 과정 분석:\n",
      "전체 시도 횟수: 30\n",
      "\n",
      "상위 5개 파라미터 조합:\n",
      "1. 점수: 0.9349 (±0.0075)\n",
      "   파라미터: OrderedDict([('learning_rate', 0.07064596568969471), ('max_depth', 6), ('n_estimators', 200), ('subsample', 0.8)])\n",
      "2. 점수: 0.9348 (±0.0076)\n",
      "   파라미터: OrderedDict([('learning_rate', 0.08313363930334089), ('max_depth', 6), ('n_estimators', 166), ('subsample', 0.8)])\n",
      "3. 점수: 0.9345 (±0.0077)\n",
      "   파라미터: OrderedDict([('learning_rate', 0.07283408237913369), ('max_depth', 8), ('n_estimators', 149), ('subsample', 0.8)])\n",
      "4. 점수: 0.9342 (±0.0080)\n",
      "   파라미터: OrderedDict([('learning_rate', 0.040343472274915984), ('max_depth', 7), ('n_estimators', 190), ('subsample', 0.8631599186974098)])\n",
      "5. 점수: 0.9342 (±0.0069)\n",
      "   파라미터: OrderedDict([('learning_rate', 0.15849201309311142), ('max_depth', 5), ('n_estimators', 140), ('subsample', 0.9605529562312621)])\n",
      "\n",
      "수렴 분석:\n",
      "초기 10회 평균 점수: 0.9342\n",
      "마지막 10회 최고 점수: 0.9349\n",
      "개선 정도: 0.0007\n"
     ]
    }
   ],
   "source": [
    "def bayesian_search_tuning(X, y):\n",
    "    \"\"\"베이지안 최적화를 활용한 하이퍼파라미터 튜닝\"\"\"\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    from skopt import BayesSearchCV\n",
    "    from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "    print(\"\\n=== 하이퍼파라미터 튜닝 (Bayesian Optimization) ===\")\n",
    "\n",
    "    # 베이지안 최적화를 위한 검색 공간 정의\n",
    "    # log-uniform 분포: 작은 값 쪽에 더 많은 샘플을 할당 → 학습률은 보통 작은 값이 성능에 큰 영향을 주기 때문에 로그 분포로 탐색하는 게 효율적\n",
    "    search_space = {\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'max_depth': Integer(4, 8),\n",
    "        'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "        'subsample': Real(0.8, 1.0)\n",
    "    }\n",
    "\n",
    "\n",
    "    # XGBoost 모델\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "\n",
    "    # BayesSearchCV 설정\n",
    "    bayes_search = BayesSearchCV(\n",
    "        estimator=xgb_model,          # 최적화를 적용할 모델\n",
    "        search_spaces=search_space,   # 탐색할 하이퍼파라미터 공간 (딕셔너리 형식)\n",
    "        n_iter=30,                    # 탐색할 반복 횟수(기본값:50), 클수록 더 좋은 해를 찾을 확률이 높지만 시간이 오래 걸림, 30~100\n",
    "        scoring='roc_auc',            # 평가지표\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        n_jobs=-1,                    # 병렬 실행 스레드 수, -1 = CPU 전체 사용\n",
    "        random_state=42,\n",
    "        verbose=0                     # 출력 로그 레벨(0 = 없음, 1 이상 = 진행 상황 출력)\n",
    "    )\n",
    "\n",
    "    # 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 베이지안 최적화 실행\n",
    "    print(\"Bayesian Optimization 실행 중...\")\n",
    "    bayes_search.fit(X_scaled, y)\n",
    "\n",
    "    dt = time.perf_counter() - t0\n",
    "    print(f\"수행 시간: {dt:.3f}s\")\n",
    "\n",
    "    print(f\"최적 파라미터: {bayes_search.best_params_}\")\n",
    "    print(f\"최적 CV 점수: {bayes_search.best_score_:.4f}\")\n",
    "\n",
    "    # 최적화 과정 분석\n",
    "    print(f\"\\n최적화 과정 분석:\")\n",
    "    print(f\"전체 시도 횟수: {len(bayes_search.cv_results_['mean_test_score'])}\")\n",
    "\n",
    "    # 상위 5개 결과 출력\n",
    "    print(\"\\n상위 5개 파라미터 조합:\")\n",
    "    results_df = pd.DataFrame(bayes_search.cv_results_)\n",
    "    top_5 = results_df.nlargest(5, 'mean_test_score')[['mean_test_score', 'std_test_score', 'params']]\n",
    "\n",
    "    for idx, (_, row) in enumerate(top_5.iterrows(), 1):\n",
    "        print(f\"{idx}. 점수: {row['mean_test_score']:.4f} (±{row['std_test_score']*2:.4f})\")\n",
    "        print(f\"   파라미터: {row['params']}\")\n",
    "\n",
    "    # 수렴 곡선 데이터 생성\n",
    "    scores_over_time = []\n",
    "    best_score_so_far = -np.inf\n",
    "    for score in bayes_search.cv_results_['mean_test_score']:\n",
    "        if score > best_score_so_far:\n",
    "            best_score_so_far = score\n",
    "        scores_over_time.append(best_score_so_far)\n",
    "\n",
    "    print(f\"\\n수렴 분석:\")\n",
    "    print(f\"초기 10회 평균 점수: {np.mean(scores_over_time[:10]):.4f}\")\n",
    "    print(f\"마지막 10회 최고 점수: {scores_over_time[-1]:.4f}\")\n",
    "    print(f\"개선 정도: {(scores_over_time[-1] - np.mean(scores_over_time[:10])):.4f}\")\n",
    "\n",
    "    return bayes_search.best_estimator_, scaler, bayes_search\n",
    "\n",
    "best_estimator_, scaler, bayes_search = bayesian_search_tuning(X_processed, y_processed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1njREubj9Et"
   },
   "source": [
    "## 6-4. HPO: Bayesian Search(TPE:Tree-structured Parzen Estimator) using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529,
     "referenced_widgets": [
      "c83bc963cad647eab0af59759f756c5e",
      "2ef31376031c49b2913935d8bdfa1754",
      "1c6e4e6d487f4b0b9046b10b98ebd311",
      "eeb98e53e79a45b7a122edaca91e1a2c",
      "7a371171f1a4423db2a6f2549c6d9425",
      "b159cabdf7cf47fa961627da1eb81807",
      "a318b8c294724640a54e784a28f791eb",
      "3e877dcd6f0a40a49e1a8a08faf935bd",
      "58ca42f0a1214e8faf4d9b0d1461884c",
      "2bd5a80bc6eb4605b1cc5bc6872c9ba5",
      "f79935a49d3144efa1df65914434689a"
     ]
    },
    "id": "WuA4lfq_j9Wz",
    "outputId": "7a8ed88a-ef76-4f96-8761-9233bab1f796"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 하이퍼파라미터 튜닝 (Optuna) ===\n",
      "Optuna 최적화 시작 (30회 시도)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f642266862422a95d12df0108c59d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수행 시간: 7.245s\n",
      "최적 AUC 점수: 0.9323\n",
      "최적 파라미터: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.053566770906231354, 'subsample': 0.8017372221127864}\n",
      "시도 횟수: 30\n",
      "\n",
      "=== 최적화 과정 분석 ===\n",
      "상위 5개 시도 결과:\n",
      "1. AUC: 0.9323, 파라미터: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.053566770906231354, 'subsample': 0.8017372221127864}\n",
      "2. AUC: 0.9323, 파라미터: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.07704669005072712, 'subsample': 0.802358795884076}\n",
      "3. AUC: 0.9323, 파라미터: {'n_estimators': 185, 'max_depth': 6, 'learning_rate': 0.054138800373132734, 'subsample': 0.8191863327780846}\n",
      "4. AUC: 0.9323, 파라미터: {'n_estimators': 169, 'max_depth': 6, 'learning_rate': 0.0957534158847779, 'subsample': 0.8242648065638125}\n",
      "5. AUC: 0.9323, 파라미터: {'n_estimators': 182, 'max_depth': 6, 'learning_rate': 0.052102913140168655, 'subsample': 0.8742760522111468}\n",
      "\n",
      "수렴 분석:\n",
      "전반부 평균 AUC: 0.9237\n",
      "후반부 평균 AUC: 0.9295\n",
      "개선 정도: 0.0058\n",
      "\n",
      "파라미터 중요도 (Top 5):\n",
      "  learning_rate: 0.5394\n",
      "  n_estimators: 0.2261\n",
      "  subsample: 0.1944\n",
      "  max_depth: 0.0400\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def optuna_search_tuning(X, y, n_trials=100):\n",
    "    \"\"\"Optuna를 활용한 하이퍼파라미터 튜닝\"\"\"\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    print(\"\\n=== 하이퍼파라미터 튜닝 (Optuna) ===\")\n",
    "\n",
    "    # 전역 변수로 데이터를 저장 (objective 함수에서 사용하기 위해)\n",
    "    global X_train_global, X_val_global, y_train_global, y_val_global, scaler_global\n",
    "\n",
    "    # 데이터 분할 및 스케일링\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # 전역 변수에 할당\n",
    "    X_train_global, X_val_global = X_train_scaled, X_val_scaled\n",
    "    y_train_global, y_val_global = y_train, y_val\n",
    "    scaler_global = scaler\n",
    "\n",
    "    def objective(trial):\n",
    "        \"\"\"Optuna objective 함수\"\"\"\n",
    "\n",
    "        # 하이퍼파라미터 제안\n",
    "        params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'logloss',\n",
    "            'random_state': 42,\n",
    "            'verbosity': 0,\n",
    "\n",
    "            # 튜닝할 하이퍼파라미터들\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 8),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.8, 1.0)\n",
    "               }\n",
    "\n",
    "        # XGBoost 모델 생성 및 훈련\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "\n",
    "        model.fit(\n",
    "            X_train_global, y_train_global,\n",
    "            eval_set=[(X_val_global, y_val_global)],\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # 검증 성능 계산\n",
    "        y_pred_proba = model.predict_proba(X_val_global)[:, 1]\n",
    "        auc_score = roc_auc_score(y_val_global, y_pred_proba)\n",
    "\n",
    "        return auc_score\n",
    "\n",
    "    # Optuna 스터디 생성\n",
    "    print(f\"Optuna 최적화 시작 ({n_trials}회 시도)...\")\n",
    "\n",
    "    # 로그 출력 줄이기\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',\n",
    "        sampler=optuna.samplers.TPESampler(seed=42),\n",
    "        pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
    "    )\n",
    "\n",
    "    # 최적화 실행\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    # 결과 출력\n",
    "    dt = time.perf_counter() - t0\n",
    "    print(f\"수행 시간: {dt:.3f}s\")\n",
    "    print(f\"최적 AUC 점수: {study.best_value:.4f}\")\n",
    "    print(f\"최적 파라미터: {study.best_params}\")\n",
    "    print(f\"시도 횟수: {len(study.trials)}\")\n",
    "\n",
    "    # 최적 모델 재훈련\n",
    "    best_params = study.best_params.copy()\n",
    "    best_params.update({\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'random_state': 42\n",
    "    })\n",
    "\n",
    "    best_model = xgb.XGBClassifier(**best_params)\n",
    "    best_model.fit(X_train_global, y_train_global)\n",
    "\n",
    "    # 최적화 과정 분석\n",
    "    print(f\"\\n=== 최적화 과정 분석 ===\")\n",
    "\n",
    "    # 상위 5개 시도 결과\n",
    "    best_trials = sorted(study.trials, key=lambda t: t.value if t.value else -np.inf, reverse=True)[:5]\n",
    "    print(\"상위 5개 시도 결과:\")\n",
    "    for i, trial in enumerate(best_trials, 1):\n",
    "        if trial.value:\n",
    "            print(f\"{i}. AUC: {trial.value:.4f}, 파라미터: {trial.params}\")\n",
    "\n",
    "    # 수렴 분석\n",
    "    values = [trial.value for trial in study.trials if trial.value is not None]\n",
    "    if len(values) >= 10:\n",
    "        early_avg = np.mean(values[:len(values)//2])\n",
    "        late_avg = np.mean(values[len(values)//2:])\n",
    "        print(f\"\\n수렴 분석:\")\n",
    "        print(f\"전반부 평균 AUC: {early_avg:.4f}\")\n",
    "        print(f\"후반부 평균 AUC: {late_avg:.4f}\")\n",
    "        print(f\"개선 정도: {late_avg - early_avg:.4f}\")\n",
    "\n",
    "    # 파라미터 중요도 분석\n",
    "    importance = optuna.importance.get_param_importances(study)\n",
    "    print(f\"\\n파라미터 중요도 (Top 5):\")\n",
    "    for param, imp in sorted(importance.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "        print(f\"  {param}: {imp:.4f}\")\n",
    "\n",
    "    return best_model, scaler_global, study\n",
    "\n",
    "best_model, scaler_global, study = optuna_search_tuning(X_processed, y_processed, n_trials=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eIkpu74ozwj2"
   },
   "source": [
    "## Task1: 위 예시 사례를 활용하고 적용모델을 달리하여 하이퍼 파라메타 최적화(HPO) 수행  \n",
    " - HPO Method 중 2개의 Method를 선정하여 비교분석 해보세요.\n",
    " - 적용 모델을 다르게.. (XGBoost 제외)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "resqMt470Bu4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 1: 다른 모델을 활용한 HPO 비교 분석 ===\n",
      "모델: Random Forest vs SVM\n",
      "HPO 방법: Grid Search vs Bayesian Optimization\n",
      "\n",
      "훈련 데이터: (36168, 16)\n",
      "테스트 데이터: (9043, 16)\n",
      "\n",
      "=== Random Forest + Grid Search ===\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "수행 시간: 323.300s\n",
      "최적 파라미터: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "최적 CV 점수: 0.9286\n",
      "\n",
      "=== Random Forest + Bayesian Optimization ===\n",
      "수행 시간: 130.856s\n",
      "최적 파라미터: OrderedDict([('max_depth', 20), ('max_features', 'sqrt'), ('min_samples_leaf', 1), ('min_samples_split', 18), ('n_estimators', 196)])\n",
      "최적 CV 점수: 0.9285\n",
      "\n",
      "=== SVM + Grid Search ===\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "수행 시간: 1117.618s\n",
      "최적 파라미터: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "최적 CV 점수: 0.8892\n",
      "\n",
      "=== SVM + Bayesian Optimization ===\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "print(\"=== Task 1: 다른 모델을 활용한 HPO 비교 분석 ===\")\n",
    "print(\"모델: Random Forest vs SVM\")\n",
    "print(\"HPO 방법: Grid Search vs Bayesian Optimization\")\n",
    "\n",
    "# 데이터 준비\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y_processed, test_size=0.2, random_state=42, stratify=y_processed\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n훈련 데이터: {X_train_scaled.shape}\")\n",
    "print(f\"테스트 데이터: {X_test_scaled.shape}\")\n",
    "\n",
    "# === 1. Random Forest with Grid Search ===\n",
    "def rf_grid_search(X_train, y_train):\n",
    "    print(\"\\n=== Random Forest + Grid Search ===\")\n",
    "    t0 = time.perf_counter()\n",
    "    \n",
    "    # Random Forest 파라미터 그리드\n",
    "    rf_param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 10, 15, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "    \n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    rf_grid_search = GridSearchCV(\n",
    "        estimator=rf_model,\n",
    "        param_grid=rf_param_grid,\n",
    "        scoring='roc_auc',\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    rf_grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    dt = time.perf_counter() - t0\n",
    "    print(f\"수행 시간: {dt:.3f}s\")\n",
    "    print(f\"최적 파라미터: {rf_grid_search.best_params_}\")\n",
    "    print(f\"최적 CV 점수: {rf_grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    return rf_grid_search.best_estimator_, dt\n",
    "\n",
    "# === 2. Random Forest with Bayesian Optimization ===\n",
    "def rf_bayesian_search(X_train, y_train):\n",
    "    print(\"\\n=== Random Forest + Bayesian Optimization ===\")\n",
    "    t0 = time.perf_counter()\n",
    "    \n",
    "    # Random Forest 검색 공간\n",
    "    rf_search_space = {\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'max_depth': Integer(5, 20),\n",
    "        'min_samples_split': Integer(2, 20),\n",
    "        'min_samples_leaf': Integer(1, 10),\n",
    "        'max_features': Categorical(['sqrt', 'log2'])\n",
    "    }\n",
    "    \n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    rf_bayes_search = BayesSearchCV(\n",
    "        estimator=rf_model,\n",
    "        search_spaces=rf_search_space,\n",
    "        n_iter=30,\n",
    "        scoring='roc_auc',\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    rf_bayes_search.fit(X_train, y_train)\n",
    "    \n",
    "    dt = time.perf_counter() - t0\n",
    "    print(f\"수행 시간: {dt:.3f}s\")\n",
    "    print(f\"최적 파라미터: {rf_bayes_search.best_params_}\")\n",
    "    print(f\"최적 CV 점수: {rf_bayes_search.best_score_:.4f}\")\n",
    "    \n",
    "    return rf_bayes_search.best_estimator_, dt\n",
    "\n",
    "# === 3. SVM with Grid Search ===\n",
    "def svm_grid_search(X_train, y_train):\n",
    "    print(\"\\n=== SVM + Grid Search ===\")\n",
    "    t0 = time.perf_counter()\n",
    "    \n",
    "    # SVM 파라미터 그리드 (작은 그리드로 시간 단축)\n",
    "    svm_param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01],\n",
    "        'kernel': ['rbf', 'linear']\n",
    "    }\n",
    "    \n",
    "    svm_model = SVC(random_state=42, probability=True)\n",
    "    \n",
    "    svm_grid_search = GridSearchCV(\n",
    "        estimator=svm_model,\n",
    "        param_grid=svm_param_grid,\n",
    "        scoring='roc_auc',\n",
    "        cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),  # 3-fold로 시간 단축\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    svm_grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    dt = time.perf_counter() - t0\n",
    "    print(f\"수행 시간: {dt:.3f}s\")\n",
    "    print(f\"최적 파라미터: {svm_grid_search.best_params_}\")\n",
    "    print(f\"최적 CV 점수: {svm_grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    return svm_grid_search.best_estimator_, dt\n",
    "\n",
    "# === 4. SVM with Bayesian Optimization ===\n",
    "def svm_bayesian_search(X_train, y_train):\n",
    "    print(\"\\n=== SVM + Bayesian Optimization ===\")\n",
    "    t0 = time.perf_counter()\n",
    "    \n",
    "    # SVM 검색 공간\n",
    "    svm_search_space = {\n",
    "        'C': Real(0.1, 100, prior='log-uniform'),\n",
    "        'gamma': Real(1e-4, 1e-1, prior='log-uniform'),\n",
    "        'kernel': Categorical(['rbf', 'linear'])\n",
    "    }\n",
    "    \n",
    "    svm_model = SVC(random_state=42, probability=True)\n",
    "    \n",
    "    svm_bayes_search = BayesSearchCV(\n",
    "        estimator=svm_model,\n",
    "        search_spaces=svm_search_space,\n",
    "        n_iter=20,\n",
    "        scoring='roc_auc',\n",
    "        cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),  # 3-fold로 시간 단축\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    svm_bayes_search.fit(X_train, y_train)\n",
    "    \n",
    "    dt = time.perf_counter() - t0\n",
    "    print(f\"수행 시간: {dt:.3f}s\")\n",
    "    print(f\"최적 파라미터: {svm_bayes_search.best_params_}\")\n",
    "    print(f\"최적 CV 점수: {svm_bayes_search.best_score_:.4f}\")\n",
    "    \n",
    "    return svm_bayes_search.best_estimator_, dt\n",
    "\n",
    "# === 모든 방법 실행 및 비교 ===\n",
    "results = {}\n",
    "\n",
    "# Random Forest 실행\n",
    "rf_grid_model, rf_grid_time = rf_grid_search(X_train_scaled, y_train)\n",
    "rf_bayes_model, rf_bayes_time = rf_bayesian_search(X_train_scaled, y_train)\n",
    "\n",
    "# SVM 실행\n",
    "svm_grid_model, svm_grid_time = svm_grid_search(X_train_scaled, y_train)\n",
    "svm_bayes_model, svm_bayes_time = svm_bayesian_search(X_train_scaled, y_train)\n",
    "\n",
    "# === 테스트 성능 평가 ===\n",
    "models = {\n",
    "    'RF + Grid Search': rf_grid_model,\n",
    "    'RF + Bayesian': rf_bayes_model,\n",
    "    'SVM + Grid Search': svm_grid_model,\n",
    "    'SVM + Bayesian': svm_bayes_model\n",
    "}\n",
    "\n",
    "times = {\n",
    "    'RF + Grid Search': rf_grid_time,\n",
    "    'RF + Bayesian': rf_bayes_time,\n",
    "    'SVM + Grid Search': svm_grid_time,\n",
    "    'SVM + Bayesian': svm_bayes_time\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"=== 최종 테스트 성능 비교 ===\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # 예측\n",
    "    if name.startswith('SVM'):\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:  # Random Forest\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # 성능 계산\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    test_results.append({\n",
    "        'Method': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc_score,\n",
    "        'Time(s)': times[name]\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  정확도: {accuracy:.4f}\")\n",
    "    print(f\"  AUC: {auc_score:.4f}\")\n",
    "    print(f\"  최적화 시간: {times[name]:.3f}s\")\n",
    "\n",
    "# 결과 DataFrame 생성\n",
    "results_df = pd.DataFrame(test_results)\n",
    "print(f\"\\n=== 종합 비교 결과 ===\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# 최고 성능 모델 찾기\n",
    "best_auc_idx = results_df['AUC'].idxmax()\n",
    "best_accuracy_idx = results_df['Accuracy'].idxmax()\n",
    "fastest_idx = results_df['Time(s)'].idxmin()\n",
    "\n",
    "print(f\"\\n=== 요약 ===\")\n",
    "print(f\"최고 AUC: {results_df.loc[best_auc_idx, 'Method']} ({results_df.loc[best_auc_idx, 'AUC']:.4f})\")\n",
    "print(f\"최고 정확도: {results_df.loc[best_accuracy_idx, 'Method']} ({results_df.loc[best_accuracy_idx, 'Accuracy']:.4f})\")\n",
    "print(f\"가장 빠른 최적화: {results_df.loc[fastest_idx, 'Method']} ({results_df.loc[fastest_idx, 'Time(s)']:.3f}s)\")\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# AUC 비교\n",
    "axes[0].bar(results_df['Method'], results_df['AUC'])\n",
    "axes[0].set_title('AUC Score Comparison')\n",
    "axes[0].set_ylabel('AUC Score')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 정확도 비교\n",
    "axes[1].bar(results_df['Method'], results_df['Accuracy'])\n",
    "axes[1].set_title('Accuracy Comparison')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 시간 비교\n",
    "axes[2].bar(results_df['Method'], results_df['Time(s)'])\n",
    "axes[2].set_title('Optimization Time Comparison')\n",
    "axes[2].set_ylabel('Time (seconds)')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXAftbbJhnvv"
   },
   "source": [
    "## Task2: 다른 데이터셋 활용하여 하이퍼 파라메타 최적화(HPO) 비교 수행  \n",
    "\n",
    "- HPO Method 중 2개의 Method를 선정하여 비교분석 해보세요.\n",
    "- 모델선택은 자유\n",
    "- 활용 데이터 : Adult(Census Income)(2)\n",
    "- https://archive.ics.uci.edu/dataset/2/adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_FeWYWahvTG",
    "outputId": "12584007-b30d-4c69-f0fa-1335ffd5a754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (48842, 15)\n",
      "Categorical Variable: ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       47879 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      47876 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48568 non-null  object\n",
      " 14  income          48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n",
      "Info: None\n",
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country income  \n",
      "0          2174             0              40  United-States  <=50K  \n",
      "1             0             0              13  United-States  <=50K  \n",
      "2             0             0              40  United-States  <=50K  \n",
      "3             0             0              40  United-States  <=50K  \n",
      "4             0             0              40           Cuba  <=50K  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "\n",
    "# UCI에서 데이터 불러오기\n",
    "adult = fetch_ucirepo(id=2)\n",
    "\n",
    "X = adult.data.features\n",
    "y = adult.data.targets\n",
    "\n",
    "# Concatenate후 살펴보기\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "print(f\"Data Shape: {df.shape}\")\n",
    "print(f\"Categorical Variable: {X.select_dtypes(include=['object']).columns.tolist()}\")\n",
    "print(f\"Info: {df.info()}\")\n",
    "\n",
    "print(f\"{df.head(5)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1c6e4e6d487f4b0b9046b10b98ebd311": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e877dcd6f0a40a49e1a8a08faf935bd",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_58ca42f0a1214e8faf4d9b0d1461884c",
      "value": 30
     }
    },
    "2bd5a80bc6eb4605b1cc5bc6872c9ba5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ef31376031c49b2913935d8bdfa1754": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b159cabdf7cf47fa961627da1eb81807",
      "placeholder": "​",
      "style": "IPY_MODEL_a318b8c294724640a54e784a28f791eb",
      "value": "Best trial: 28. Best value: 0.932869: 100%"
     }
    },
    "3e877dcd6f0a40a49e1a8a08faf935bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58ca42f0a1214e8faf4d9b0d1461884c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a371171f1a4423db2a6f2549c6d9425": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a318b8c294724640a54e784a28f791eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b159cabdf7cf47fa961627da1eb81807": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c83bc963cad647eab0af59759f756c5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ef31376031c49b2913935d8bdfa1754",
       "IPY_MODEL_1c6e4e6d487f4b0b9046b10b98ebd311",
       "IPY_MODEL_eeb98e53e79a45b7a122edaca91e1a2c"
      ],
      "layout": "IPY_MODEL_7a371171f1a4423db2a6f2549c6d9425"
     }
    },
    "eeb98e53e79a45b7a122edaca91e1a2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bd5a80bc6eb4605b1cc5bc6872c9ba5",
      "placeholder": "​",
      "style": "IPY_MODEL_f79935a49d3144efa1df65914434689a",
      "value": " 30/30 [00:19&lt;00:00,  1.81it/s]"
     }
    },
    "f79935a49d3144efa1df65914434689a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
