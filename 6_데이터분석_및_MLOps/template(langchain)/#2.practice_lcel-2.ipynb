{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ë‹¤ìŒ ì‹¤ìŠµ ì½”ë“œëŠ” í•™ìŠµ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš© ë°”ëë‹ˆë‹¤. ë¬¸ì˜ : audit@korea.ac.kr ì„ì„±ì—´ Ph.D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1. ë™ì‘ì— í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv openai faiss-cpu langchain pypdf tiktoken\n",
    "%pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2. LLM ì—°ê²° API Key ì„¤ì • </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 3. PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswaniâˆ—\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeerâˆ—\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmarâˆ—\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreitâˆ—\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jonesâˆ—\n",
      "Google Research\n",
      "llion@google.com\n",
      "Aidan N. Gomezâˆ— â€ \n",
      "University of Toronto\n",
      "aidan@cs.toronto.edu\n",
      "Åukasz Kaiserâˆ—\n",
      "Google Brain\n",
      "lukaszkaiser@google.com\n",
      "Illia Polosukhinâˆ— â€¡\n",
      "illia.polosukhin@gmail.com\n",
      "Abstract\n",
      "The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks that include an encoder and a decoder. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer,\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Exp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pypdf import PdfReader\n",
    "\n",
    "def load_pdf_text(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆ\n",
    "pdf_path = \"./attention.pdf\"  # ê°™ì€ í´ë”ì— PDFê°€ ìˆì–´ì•¼ í•¨\n",
    "raw_text = load_pdf_text(pdf_path)\n",
    "print(raw_text[:1000])  # ì²˜ìŒ 1000ìë§Œ ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 4. í…ìŠ¤íŠ¸ ë¶„í•  </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89ê°œ ë¬¸ë‹¨ ìƒì„±ë¨\n",
      "page_content='Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswaniâˆ—\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeerâˆ—\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmarâˆ—\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreitâˆ—\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jonesâˆ—\n",
      "Google Research\n",
      "llion@google.com\n",
      "Aidan N. Gomezâˆ— â€ \n",
      "University of Toronto\n",
      "aidan@cs.toronto.edu'\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "def split_text(text, chunk_size=500, chunk_overlap=50):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.create_documents([text])\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆ\n",
    "documents = split_text(raw_text)\n",
    "print(f\"{len(documents)}ê°œ ë¬¸ë‹¨ ìƒì„±ë¨\")\n",
    "print(documents[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 5. ë²¡í„° ì„ë² ë”© ë° ë²¡í„° DB (FAISS) ì¸ë±ì‹± </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ìƒì„±\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# ë²¡í„° DB ìƒì„±\n",
    "vector_db = FAISS.from_documents(documents, embedding_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 6. ì‚¬ìš©ì ì¿¼ë¦¬ì— ëŒ€í•œ ê²€ìƒ‰ </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] reduced to a constant number of operations, albeit at the cost of reduced effective resolution due\n",
      "to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\n",
      "described in section 3.2.\n",
      "Self-attention, sometimes called intra-attention is an attention mechanism rela...\n",
      "\n",
      "[2] Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\n",
      "tion models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
      "the input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\n",
      "a...\n",
      "\n",
      "[3] The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "Figure 5: Many of the attention heads exhibit ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def retrieve_docs(query, db, k=3):\n",
    "    return db.similarity_search(query, k=k)\n",
    "\n",
    "# ì˜ˆì‹œ ì¿¼ë¦¬\n",
    "query = \"ì´ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ Attentionê³¼ Self-Atteionì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "matched_docs = retrieve_docs(query, vector_db)\n",
    "for i, doc in enumerate(matched_docs):\n",
    "    print(f\"[{i+1}] {doc.page_content[:300]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 7. LLMìœ¼ë¡œ ë‹µë³€ ìƒì„± </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¡ ë‹µë³€:\n",
      "\n",
      "Attentionê³¼ Self-Attentionì€ ëª¨ë‘ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì´ì§€ë§Œ, ê·¸ ëª©ì ê³¼ ì ìš© ë°©ì‹ì—ì„œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. **Attention**:\n",
      "   - Attention ë©”ì»¤ë‹ˆì¦˜ì€ ì…ë ¥ ë˜ëŠ” ì¶œë ¥ ì‹œí€€ìŠ¤ ë‚´ì˜ ì„œë¡œ ë‹¤ë¥¸ ìœ„ì¹˜ ê°„ì˜ ì˜ì¡´ì„±ì„ ëª¨ë¸ë§í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ëŠ” ì…ë ¥ ì‹œí€€ìŠ¤ì˜ íŠ¹ì • ë¶€ë¶„ì— ë” ë§ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ëª¨ë¸ì´ ì¤‘ìš”í•œ ì •ë³´ì— ì§‘ì¤‘í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
      "   - Attentionì€ ì£¼ë¡œ ì‹œí€€ìŠ¤-íˆ¬-ì‹œí€€ìŠ¤ ëª¨ë¸ì—ì„œ ì‚¬ìš©ë˜ë©°, íŠ¹íˆ ì…ë ¥ê³¼ ì¶œë ¥ ì‹œí€€ìŠ¤ ê°„ì˜ ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.\n",
      "   - ì „í†µì ìœ¼ë¡œ Attentionì€ RNNê³¼ ê°™ì€ ìˆœí™˜ ì‹ ê²½ë§ê³¼ í•¨ê»˜ ì‚¬ìš©ë˜ì–´ ì™”ìŠµë‹ˆë‹¤. ì´ëŠ” ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ì— ê´€ê³„ì—†ì´ ì˜ì¡´ì„±ì„ ëª¨ë¸ë§í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **Self-Attention**:\n",
      "   - Self-Attention, ë˜ëŠ” Intra-Attentionì€ ë‹¨ì¼ ì‹œí€€ìŠ¤ ë‚´ì˜ ì„œë¡œ ë‹¤ë¥¸ ìœ„ì¹˜ ê°„ì˜ ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì…ë‹ˆë‹¤. ì´ëŠ” ì‹œí€€ìŠ¤ì˜ ê° ìœ„ì¹˜ê°€ ë‹¤ë¥¸ ëª¨ë“  ìœ„ì¹˜ì™€ì˜ ê´€ê³„ë¥¼ ê³ ë ¤í•˜ì—¬ ì‹œí€€ìŠ¤ì˜ í‘œí˜„ì„ ê³„ì‚°í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "   - Self-Attentionì€ Transformerì™€ ê°™ì€ ëª¨ë¸ì—ì„œ í•µì‹¬ì ì¸ ì—­í• ì„ í•˜ë©°, ìˆœí™˜ êµ¬ì¡° ì—†ì´ë„ ì‹œí€€ìŠ¤ ë‚´ì˜ ëª¨ë“  ìœ„ì¹˜ ê°„ì˜ ì˜ì¡´ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ ëª¨ë¸ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "   - Self-Attentionì€ íŠ¹íˆ ê¸´ ì‹œí€€ìŠ¤ì—ì„œë„ ë³‘ë ¬ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆì–´, ê³„ì‚° íš¨ìœ¨ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
      "\n",
      "ë…¼ë¬¸ì—ì„œëŠ” Transformer ëª¨ë¸ì´ ìˆœí™˜ êµ¬ì¡°ë¥¼ ë°°ì œí•˜ê³  Self-Attention ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì‹œí€€ìŠ¤ ë‚´ì˜ ì˜ì¡´ì„±ì„ ëª¨ë¸ë§í•œë‹¤ê³  ì„¤ëª…í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” Attention ë©”ì»¤ë‹ˆì¦˜ì´ RNNê³¼ í•¨ê»˜ ì‚¬ìš©ë˜ëŠ” ê¸°ì¡´ ë°©ì‹ê³¼ ëŒ€ë¹„ë©ë‹ˆë‹¤. Self-Attentionì€ ì—¬ëŸ¬ í—¤ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì‹œí€€ìŠ¤ë¥¼ ë¶„ì„í•  ìˆ˜ ìˆë„ë¡ í•˜ë©°, ì´ëŠ” ëª¨ë¸ì˜ í‘œí˜„ë ¥ì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def generate_answer(docs, user_query):\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    prompt = f\"\"\"ë‹¤ìŒì€ ë…¼ë¬¸ì—ì„œ ë°œì·Œí•œ ë‚´ìš©ì…ë‹ˆë‹¤:\\n\\n{context}\\n\\nì‚¬ìš©ì ì§ˆë¬¸: {user_query}\\n\\në…¼ë¬¸ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\"\"\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.3)\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return response.content\n",
    "\n",
    "# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°\n",
    "# query = input(\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "query = \"Attentionê³¼ Self-Attentionì„ ë¹„êµí•˜ì‹œì˜¤.\"\n",
    "\n",
    "# ë‹µë³€ ìƒì„±\n",
    "answer = generate_answer(matched_docs, query)\n",
    "print(\"\\nğŸ’¡ ë‹µë³€:\\n\")\n",
    "print(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
