{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ë‹¤ìŒ ì‹¤ìŠµ ì½”ë“œëŠ” í•™ìŠµ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš© ë°”ëë‹ˆë‹¤. ë¬¸ì˜ : audit@korea.ac.kr ì„ì„±ì—´ Ph.D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. ë…¸ë“œ ë‚´ë¶€ì—ì„œ íˆ´ ì„ íƒ : ê° ë…¸ë“œë¥¼ í•¨ìˆ˜ì²˜ëŸ¼ ì •ì˜í•˜ê³ , ê·¸ ì•ˆì—ì„œ í•„ìš”í•œ íˆ´ì„ ì§ì ‘ í˜¸ì¶œí•˜ë„ë¡ ì½”ë“œë¥¼ ì‘ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langgraph langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°\n",
    "# openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# serpapi_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "# ë˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì§ì ‘ í‚¤ ì…ë ¥ (ê°œë°œ)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\"  # ìì‹ ì˜ OpenAI í‚¤\n",
    "# os.environ[\"SERPAPI_API_KEY\"] = \"9c61eeb3bac82aea465b08d257b1a419dbf02d1734808b80cae1e881ae796196\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM ì„¤ì • (ì˜ˆ: gpt-4)\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ ì„í¬íŠ¸\n",
    "from typing import TypedDict, Literal\n",
    "import re, ast, operator, hashlib\n",
    "from langgraph.graph import StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒíƒœ ì •ì˜\n",
    "class State(TypedDict, total=False):\n",
    "    query: str\n",
    "    route: Literal[\"web\", \"math\"]\n",
    "    result: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_math_query(query: str) -> bool:\n",
    "    \"\"\"\n",
    "    ë‹¨ìˆœí•˜ê²Œ ìˆ˜í•™ ì—°ì‚° ì—¬ë¶€ë¥¼ íŒë³„í•˜ëŠ” í•¨ìˆ˜.\n",
    "    ìˆ«ìì™€ ì‚¬ì¹™ì—°ì‚° ê¸°í˜¸ë§Œ í¬í•¨ë˜ë©´ True ë°˜í™˜.\n",
    "    \"\"\"\n",
    "    return bool(re.fullmatch(r\"[0-9+\\-*/(). ]+\", query.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ìˆ˜í•™ì‹ íŒë³„)\n",
    "_ARITH_RE = re.compile(r\"^\\s*[-+*/\\d\\s().]+\\s*$\")\n",
    "\n",
    "def is_math_query(q: str) -> bool:\n",
    "    return bool(_ARITH_RE.match(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë…¸ë“œ êµ¬í˜„ (ì›¹ ê²€ìƒ‰ / ìˆ˜í•™ ê³„ì‚°)\n",
    "# ì›¹ ê²€ìƒ‰ ë…¸ë“œ (ì—¬ê¸°ì„œëŠ” ë”ë¯¸ í•¨ìˆ˜ë¡œ ëŒ€ì²´)\n",
    "def web_scraper(query: str, num_results: int = 5) -> str:\n",
    "    \"\"\"êµ¬ê¸€ì—ì„œ ê²€ìƒ‰ì–´ì— ëŒ€í•œ ìƒìœ„ ìš”ì•½ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        serpapi_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "        params = {\n",
    "            \"engine\": \"google\",\n",
    "            \"q\": query,\n",
    "            \"hl\": \"ko\",\n",
    "            \"gl\": \"kr\",\n",
    "            \"api_key\": serpapi_key\n",
    "        }\n",
    "\n",
    "        search = GoogleSearch(params)\n",
    "        results = search.get_dict()\n",
    "\n",
    "        if \"organic_results\" not in results or not results[\"organic_results\"]:\n",
    "            return \"ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\"\n",
    "\n",
    "        titles = [res.get(\"title\", \"ì œëª© ì—†ìŒ\") for res in results[\"organic_results\"][:num_results]]\n",
    "        return \"\\n\".join(f\"- {title}\" for title in titles)\n",
    "    except Exception as e:\n",
    "        return f\"ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "# web_nodeëŠ” web_scraper íˆ´ë§Œ ì‹¤í–‰í•˜ë„ë¡ ê³ ì •ë¨\n",
    "def web_node(state: State) -> State:\n",
    "    q = state[\"query\"]\n",
    "    try:\n",
    "        summary = web_scraper(q) # web_nodeëŠ” ë¬´ì¡°ê±´ web_scraperë§Œ í˜¸ì¶œ\n",
    "    except Exception as e:\n",
    "        summary = f\"ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}\"\n",
    "    return {\"result\": f\"[ì›¹ê²€ìƒ‰ ìš”ì•½]\\n{summary}\"}\n",
    "\n",
    "\n",
    "# ìˆ˜í•™ ê³„ì‚° ë…¸ë“œ\n",
    "_ops = {\n",
    "    ast.Add: operator.add, ast.Sub: operator.sub,\n",
    "    ast.Mult: operator.mul, ast.Div: operator.truediv,\n",
    "    ast.USub: operator.neg, ast.UAdd: operator.pos,\n",
    "    ast.Pow: operator.pow,\n",
    "}\n",
    "\n",
    "def _eval_expr(node):\n",
    "    if isinstance(node, ast.Num):\n",
    "        return node.n\n",
    "    if isinstance(node, ast.Constant) and isinstance(node.value, (int, float)):\n",
    "        return node.value\n",
    "    if isinstance(node, ast.BinOp) and type(node.op) in _ops:\n",
    "        return _ops[type(node.op)](_eval_expr(node.left), _eval_expr(node.right))\n",
    "    if isinstance(node, ast.UnaryOp) and type(node.op) in _ops:\n",
    "        return _ops[type(node.op)](_eval_expr(node.operand))\n",
    "    raise ValueError(\"í—ˆìš©ë˜ì§€ ì•Šì€ ì—°ì‚°ì…ë‹ˆë‹¤.\")\n",
    "\n",
    "# math_nodeëŠ” ì‚°ìˆ  ê³„ì‚° íˆ´(_eval_expr)ë§Œ ì‹¤í–‰í•˜ë„ë¡ ê³ ì •ë¨\n",
    "def math_node(state: State) -> State:\n",
    "    q = state[\"query\"]\n",
    "    try:\n",
    "        node = ast.parse(q, mode=\"eval\").body\n",
    "        val = _eval_expr(node) # math_nodeëŠ” ë¬´ì¡°ê±´ _eval_exprë§Œ í˜¸ì¶œ\n",
    "        return {\"result\": f\"[ê³„ì‚° ê²°ê³¼] {q} = {val}\"}\n",
    "    except Exception:\n",
    "        return {\"result\": \"ìœ íš¨í•œ ì‚°ìˆ ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¼ìš°í„° ë…¸ë“œ (ì§ˆë¬¸ì— ë”°ë¼ web/math ë¶„ê¸°)\n",
    "def router(state: State) -> State:\n",
    "    q = state[\"query\"]\n",
    "    route: Literal[\"web\",\"math\"] = \"math\" if is_math_query(q) else \"web\"\n",
    "    return {\"route\": route}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë˜í”„ ë¹Œë“œ\n",
    "def build_graph():\n",
    "    builder = StateGraph(State)\n",
    "\n",
    "    builder.add_node(\"router\", router)\n",
    "    builder.add_node(\"web_node\", web_node)\n",
    "    builder.add_node(\"math_node\", math_node)\n",
    "\n",
    "    # router â†’ ì¡°ê±´ ë¶„ê¸°\n",
    "    builder.add_conditional_edges(\n",
    "        \"router\",\n",
    "        lambda s: s[\"route\"],\n",
    "        {\n",
    "            \"web\": \"web_node\",\n",
    "            \"math\": \"math_node\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    builder.set_entry_point(\"router\")\n",
    "    return builder.compile()\n",
    "\n",
    "graph = build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '3 + 5', 'route': 'math', 'result': '[ê³„ì‚° ê²°ê³¼] 3 + 5 = 8'}\n",
      "{'query': 'LangGraph ì‚¬ìš©ë²•', 'route': 'web', 'result': '[ì›¹ê²€ìƒ‰ ìš”ì•½]\\n- Part 1. ë­ê·¸ë˜í”„ LangGraph ê¸°ì´ˆ\\n- LangGraph) LangGraphì— ëŒ€í•œ ê°œë…ê³¼ ê°„ë‹¨í•œ ì˜ˆì‹œ ë§Œë“¤ì–´ë³´ê¸°\\n- 1-2. LangGraph í™˜ê²½ ì„¤ì • ë° ê¸°ë³¸ ì‚¬ìš©ë²•\\n- ë­ê·¸ë˜í”„(LangGraph)ë€? LangGraphì˜ ê°œë…ê³¼ ì‚¬ìš© ë°©ë²• ì˜ˆì œ ...\\n- LangGraph Retrieval Agentë¥¼ í™œìš©í•œ ë™ì  ë¬¸ì„œ ê²€ìƒ‰ ë° ì²˜ë¦¬'}\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n",
    "print(graph.invoke({\"query\": \"3 + 5\"}))            # ìˆ˜í•™ â†’ math_node\n",
    "print(graph.invoke({\"query\": \"LangGraph ì‚¬ìš©ë²•\"})) # ì¼ë°˜ ì§ˆë¬¸ â†’ web_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. AgentExecutor + Tool Routing : LangChain ìŠ¤íƒ€ì¼ë¡œ, ë…¸ë“œ ì•ˆì—ì„œ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³ , ì—ì´ì „íŠ¸ì— ì–´ë–¤ íˆ´ ì„¸íŠ¸ë¥¼ ì¤„ì§€ ì§€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„í¬íŠ¸\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# ê³µí†µ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "base_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë„êµ¬ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì‹œ: ì›¹ ê²€ìƒ‰ íˆ´\n",
    "from langchain.tools import tool\n",
    "# SerpAPIìš© ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "@tool\n",
    "def web_scraper(query: str, num_results: int = 5) -> str:\n",
    "    \"\"\"êµ¬ê¸€ì—ì„œ ê²€ìƒ‰ì–´ì— ëŒ€í•œ ìƒìœ„ ìš”ì•½ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        serpapi_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "        params = {\n",
    "            \"engine\": \"google\",\n",
    "            \"q\": query,\n",
    "            \"hl\": \"ko\",\n",
    "            \"gl\": \"kr\",\n",
    "            \"api_key\": serpapi_key\n",
    "        }\n",
    "\n",
    "        search = GoogleSearch(params)\n",
    "        results = search.get_dict()\n",
    "\n",
    "        if \"organic_results\" not in results or not results[\"organic_results\"]:\n",
    "            return \"ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\"\n",
    "\n",
    "        titles = [res.get(\"title\", \"ì œëª© ì—†ìŒ\") for res in results[\"organic_results\"][:num_results]]\n",
    "        return \"\\n\".join(f\"- {title}\" for title in titles)\n",
    "    except Exception as e:\n",
    "        return f\"ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "# ì˜ˆì‹œ: ìˆ˜í•™ ë§ì…ˆ íˆ´\n",
    "@tool\n",
    "def calc_add(x: int, y: int) -> int:\n",
    "    \"\"\"ë‘ ìˆ«ìë¥¼ ë”í•œë‹¤.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "# ğŸ”¹ ê°ê° íˆ´ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ì–´ì¤Œ\n",
    "tools_web = [web_scraper]\n",
    "tools_math = [calc_add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›¹ê²€ìƒ‰ AgentExecutor\n",
    "agent_web = create_openai_functions_agent(\n",
    "    llm=llm,\n",
    "    tools=tools_web, # ì›¹ê²€ìƒ‰ Tool : web_scraperì„ ì“°ë„ë¡ ì§€ì •\n",
    "    prompt=base_prompt\n",
    ")\n",
    "exec_web = AgentExecutor(agent=agent_web, tools=tools_web, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³„ì‚° AgentExecutor\n",
    "agent_math = create_openai_functions_agent(\n",
    "    llm=llm,\n",
    "    tools=tools_math, # ì‚°ìˆ ì—°ì‚° Tool : calc_addì„ ì“°ë„ë¡ ì§€ì •\n",
    "    prompt=base_prompt\n",
    ")\n",
    "exec_math = AgentExecutor(agent=agent_math, tools=tools_math, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_scraper` with `{'query': 'LangChain', 'num_results': 5}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m- LangChain\n",
      "- ë­ì²´ì¸ LangChain ì´ë€ ë¬´ì—‡ì¸ê°€? | ì¸ì‚¬ì´íŠ¸ë¦¬í¬íŠ¸\n",
      "- LangChainì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "- langchain-ai/langchain: ğŸ¦œğŸ”— Build context-aware reasoning ...\n",
      "- Part 1. LangChain ê¸°ì´ˆ\u001b[0m\u001b[32;1m\u001b[1;3mLangChainì€ AI ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ê³ ê¸‰ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°œë°œìë“¤ì´ ëª…ë ¹ì˜ ë§¥ë½ì„ ì´í•´í•˜ê³ , ê·¸ì— ë”°ë¼ ë°˜ì‘í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤. LangChainì€ ëŒ€í™”í˜• ì‘ìš© í”„ë¡œê·¸ë¨, ë°ì´í„° ë¶„ì„ ë° ìì—°ì–´ ì²˜ë¦¬(NLP) ì‘ì—…ì— ì í•©í•˜ë©°, ì—¬ëŸ¬ ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ ì‚¬ìš©ì ë§ì¶¤í˜• ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤. \n",
      "\n",
      "íŠ¹íˆ LangChainì€ ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” íŠ¹ì§•ì„ ê°–ê³  ìˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ë§¥ë½ ì¸ì‹**: ì–¸ì–´ ëª¨ë¸ì´ ì´ì „ ëŒ€í™”ë‚˜ ëª…ë ¹ì˜ ë§¥ë½ì„ íŒŒì•…í•˜ì—¬ ë” ì˜ë¯¸ ìˆëŠ” ë°˜ì‘ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "2. **ëª¨ë“ˆí˜• êµ¬ì¡°**: ê°œë°œìê°€ ì‰½ê²Œ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆì–´ ìœ ì—°ì„±ì´ ë†’ìŠµë‹ˆë‹¤.\n",
      "3. **ë‹¤ì–‘í•œ ì‚¬ìš© ì‚¬ë¡€**: ëŒ€í™”í˜• ì±—ë´‡, ì‚¬ìš©ì ë°ì´í„° ë¶„ì„, ì½˜í…ì¸  ìƒì„± ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "LangChainì€ AIì™€ ì–¸ì–´ ì²˜ë¦¬ì˜ í†µí•©ì„ í†µí•´ ê°œë°œìì™€ ê¸°ì—…ì´ ë” íš¨ìœ¨ì ìœ¼ë¡œ ì‘ì—…í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” í˜ì‹ ì ì¸ ë„êµ¬ë¡œ ìë¦¬ ì¡ê³  ìˆìŠµë‹ˆë‹¤.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'LangChainì„ ê²€ìƒ‰í•´ì„œ ìš”ì•½í•˜ë¼', 'chat_history': [], 'output': 'LangChainì€ AI ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ê³ ê¸‰ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°œë°œìë“¤ì´ ëª…ë ¹ì˜ ë§¥ë½ì„ ì´í•´í•˜ê³ , ê·¸ì— ë”°ë¼ ë°˜ì‘í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤. LangChainì€ ëŒ€í™”í˜• ì‘ìš© í”„ë¡œê·¸ë¨, ë°ì´í„° ë¶„ì„ ë° ìì—°ì–´ ì²˜ë¦¬(NLP) ì‘ì—…ì— ì í•©í•˜ë©°, ì—¬ëŸ¬ ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ ì‚¬ìš©ì ë§ì¶¤í˜• ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤. \\n\\níŠ¹íˆ LangChainì€ ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” íŠ¹ì§•ì„ ê°–ê³  ìˆìŠµë‹ˆë‹¤:\\n\\n1. **ë§¥ë½ ì¸ì‹**: ì–¸ì–´ ëª¨ë¸ì´ ì´ì „ ëŒ€í™”ë‚˜ ëª…ë ¹ì˜ ë§¥ë½ì„ íŒŒì•…í•˜ì—¬ ë” ì˜ë¯¸ ìˆëŠ” ë°˜ì‘ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n2. **ëª¨ë“ˆí˜• êµ¬ì¡°**: ê°œë°œìê°€ ì‰½ê²Œ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆì–´ ìœ ì—°ì„±ì´ ë†’ìŠµë‹ˆë‹¤.\\n3. **ë‹¤ì–‘í•œ ì‚¬ìš© ì‚¬ë¡€**: ëŒ€í™”í˜• ì±—ë´‡, ì‚¬ìš©ì ë°ì´í„° ë¶„ì„, ì½˜í…ì¸  ìƒì„± ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\nLangChainì€ AIì™€ ì–¸ì–´ ì²˜ë¦¬ì˜ í†µí•©ì„ í†µí•´ ê°œë°œìì™€ ê¸°ì—…ì´ ë” íš¨ìœ¨ì ìœ¼ë¡œ ì‘ì—…í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” í˜ì‹ ì ì¸ ë„êµ¬ë¡œ ìë¦¬ ì¡ê³  ìˆìŠµë‹ˆë‹¤.'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `calc_add` with `{'x': 3, 'y': 5}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m8\u001b[0m\u001b[32;1m\u001b[1;3m3ê³¼ 5ë¥¼ ë”í•˜ë©´ 8ì…ë‹ˆë‹¤.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '3ê³¼ 5ë¥¼ ë”í•˜ë¼', 'chat_history': [], 'output': '3ê³¼ 5ë¥¼ ë”í•˜ë©´ 8ì…ë‹ˆë‹¤.'}\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(exec_web.invoke({\"input\": \"LangChainì„ ê²€ìƒ‰í•´ì„œ ìš”ì•½í•˜ë¼\", \"chat_history\": []}))\n",
    "print(exec_math.invoke({\"input\": \"3ê³¼ 5ë¥¼ ë”í•˜ë¼\", \"chat_history\": []}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
