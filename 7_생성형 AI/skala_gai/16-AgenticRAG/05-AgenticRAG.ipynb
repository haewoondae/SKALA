{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260a88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc04f592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55189c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH15-Agentic-RAG\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"CH15-Agentic-RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caa91e2",
   "metadata": {},
   "source": [
    "# Agentic RAG\n",
    "\n",
    "= NaiveRAG + RelevanceCheck + WebSearch + QueryRewrite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58b43d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "from typing import Annotated, Literal, Sequence, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangChain imports\n",
    "from langchain import hub\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# Custom imports\n",
    "from langchain_opentutorial.rag.pdf import PDFRetrievalChain\n",
    "from langchain_teddynote.messages import random_uuid, stream_graph\n",
    "from langchain_teddynote.models import LLMs, get_model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744d91d9",
   "metadata": {},
   "source": [
    "## 1. 데이터 및 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34853ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로 설정\n",
    "file_path = [\"data/SPRi AI Brief_Special_AI Agent_241209_F.pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ebab021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 체인 생성\n",
    "pdf_file = PDFRetrievalChain(file_path).create_chain()\n",
    "pdf_retriever = pdf_file.retriever\n",
    "pdf_chain = pdf_file.chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d71d6dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 문서를 기반으로 검색 도구 생성\n",
    "retriever_tool = create_retriever_tool(\n",
    "    pdf_retriever,\n",
    "    \"pdf_retriever\",\n",
    "    \"Search and return information about SPRI AI Brief PDF file. It contains useful information on recent AI Agent trends. The document is published on Dec 2024.\",\n",
    "    document_prompt=PromptTemplate.from_template(\n",
    "        \"<document><context>{page_content}</context><metadata><source>{source}</source><page>{page}</page></metadata></document>\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 생성된 검색 도구를 도구 리스트에 추가\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc311fc",
   "metadata": {},
   "source": [
    "## 2. 상태 및 모델 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d525503",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"에이전트 상태 정의\"\"\"\n",
    "\n",
    "    # add_messages reducer 함수를 사용하여 메시지 시퀀스를 관리\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7606ef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최신 모델이름 가져오기\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56208447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grade(BaseModel):\n",
    "    \"\"\"관련성 평가를 위한 이진 점수 모델\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Response 'yes' if the document is relevant to the question or 'no' if it is not.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15940109",
   "metadata": {},
   "source": [
    "## 3. 노드 함수 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9a7c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"문서 관련성 평가 함수\"\"\"\n",
    "    # LLM 모델 초기화\n",
    "    model = ChatOpenAI(temperature=0, model=MODEL_NAME, streaming=True)\n",
    "\n",
    "    # 구조화된 출력을 위한 LLM 설정\n",
    "    llm_with_tool = model.with_structured_output(Grade)\n",
    "\n",
    "    # 프롬프트 템플릿 정의\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\\\n \n",
    "        Here is the retrieved document: \\\\n\\\\n {context} \\\\n\\\\n\n",
    "        Here is the user question: {question} \\\\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\\\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # llm + tool 바인딩 체인 생성\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    # 현재 상태에서 메시지 추출\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    question = messages[0].content\n",
    "\n",
    "    # 검색된 문서 추출\n",
    "    retrieved_docs = last_message.content\n",
    "\n",
    "    # 관련성 평가 실행\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": retrieved_docs})\n",
    "\n",
    "    # 관련성 여부 추출\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    # 관련성 여부에 따른 결정\n",
    "    if score == \"yes\":\n",
    "        print(\"==== [DECISION: DOCS RELEVANT] ====\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(\"==== [DECISION: DOCS NOT RELEVANT] ====\")\n",
    "        print(score)\n",
    "        return \"rewrite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7d8371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state):\n",
    "    \"\"\"에이전트 노드 함수\"\"\"\n",
    "    # 현재 상태에서 메시지 추출\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # LLM 모델 초기화\n",
    "    model = ChatOpenAI(temperature=0, streaming=True, model=MODEL_NAME)\n",
    "\n",
    "    # retriever tool 바인딩\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    # 에이전트 응답 생성\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # 기존 리스트에 추가되므로 리스트 형태로 반환\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b16da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    \"\"\"질문 재작성 노드 함수\"\"\"\n",
    "    print(\"==== [QUERY REWRITE] ====\")\n",
    "    # 현재 상태에서 메시지 추출\n",
    "    messages = state[\"messages\"]\n",
    "    # 원래 질문 추출\n",
    "    question = messages[0].content\n",
    "\n",
    "    # 질문 개선을 위한 프롬프트 구성\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\\\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\\\n \n",
    "    Here is the initial question:\n",
    "    \\\\n ------- \\\\n\n",
    "\n",
    "    {question} \n",
    "    \\\\n ------- \\\\n\n",
    "\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # LLM 모델로 질문 개선\n",
    "    model = ChatOpenAI(temperature=0, model=MODEL_NAME, streaming=True)\n",
    "    # Query-Transform 체인 실행\n",
    "    response = model.invoke(msg)\n",
    "\n",
    "    # 재작성된 질문 반환\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24584c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"최종 답변 생성 노드 함수\"\"\"\n",
    "    # 현재 상태에서 메시지 추출\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # 원래 질문 추출\n",
    "    question = messages[0].content\n",
    "\n",
    "    # 가장 마지막 메시지 추출\n",
    "    docs = messages[-1].content\n",
    "\n",
    "    # RAG 프롬프트 템플릿 가져오기\n",
    "    prompt = hub.pull(\"teddynote/rag-prompt\")\n",
    "\n",
    "    # LLM 모델 초기화\n",
    "    llm = ChatOpenAI(model_name=MODEL_NAME, temperature=0, streaming=True)\n",
    "\n",
    "    # RAG 체인 구성\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # 답변 생성 실행\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772104d2",
   "metadata": {},
   "source": [
    "## 4. 그래프 구성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2025287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워크플로우 생성\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"agent\", agent)  # 에이전트 노드\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "workflow.add_node(\"retrieve\", retrieve)  # 검색 노드\n",
    "workflow.add_node(\"rewrite\", rewrite)  # 질문 재작성 노드\n",
    "workflow.add_node(\"generate\", generate)  # 관련 문서 확인 후 응답 생성 노드\n",
    "\n",
    "# 엣지 추가\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    grade_documents,\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c98f479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Visualize Graph Error: Failed to render the graph using the Mermaid.INK API. Status code: 502.\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f2bd7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    +-----------+                \n",
      "                    | __start__ |                \n",
      "                    +-----------+                \n",
      "                           *                     \n",
      "                           *                     \n",
      "                           *                     \n",
      "                      +-------+                  \n",
      "                      | agent |.                 \n",
      "                   ...+-------+ ....             \n",
      "                ...        *        ....         \n",
      "            ....           *            ...      \n",
      "          ..               *               ....  \n",
      "+----------+               *                   ..\n",
      "| retrieve |               *                    .\n",
      "+----------+....           *                    .\n",
      "      .         ...        *                    .\n",
      "      .            ....    *                    .\n",
      "      .                ..  *                    .\n",
      "+----------+          +---------+              ..\n",
      "| generate |          | rewrite |          ....  \n",
      "+----------+****      +---------+       ...      \n",
      "                ***                 ....         \n",
      "                   ****         ....             \n",
      "                       **     ..                 \n",
      "                      +---------+                \n",
      "                      | __end__ |                \n",
      "                      +---------+                \n"
     ]
    }
   ],
   "source": [
    "print(graph.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05d9bf1",
   "metadata": {},
   "source": [
    "## 5. 그래프 실행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc206b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정 초기화\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "280ef221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==== [DECISION: DOCS RELEVANT] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "구글의 Project Astra는 보편적인 AI 에이전트를 개발하는 프로젝트로, AI 기술을 활용하여 사용자 경험을 극대화하고 다양한 산업에 적용 가능한 AI 에이전트를 제공하는 것을 목표로 합니다. 이 프로젝트는 다중모드 정보를 처리하고 사용자의 상황을 이해하며 자연스럽게 대화할 수 있는 AI 어시스턴트를 탐구합니다.\n",
      "\n",
      "**Source**\n",
      "- data/SPRi AI Brief_Special_AI Agent_241209_F.pdf (page 6)\n",
      "- data/SPRi AI Brief_Special_AI Agent_241209_F.pdf (page 7)\n",
      "- data/SPRi AI Brief_Special_AI Agent_241209_F.pdf (page 8)"
     ]
    }
   ],
   "source": [
    "# 문서 검색 기반 질문\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"구글이 진행하고 있는 Project Astra는 무엇?\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(graph, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "366064af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==== [DECISION: DOCS NOT RELEVANT] ====\n",
      "no\n",
      "==== [QUERY REWRITE] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mrewrite\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "What are the key policies and actions of President Donald Trump during his time in office?\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==== [DECISION: DOCS NOT RELEVANT] ====\n",
      "no\n",
      "==== [QUERY REWRITE] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mrewrite\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "What are the key policies and actions of President Donald Trump during his time in office?\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "During his presidency, Donald Trump implemented a range of key policies and actions across various domains. Here are some notable ones:\n",
      "\n",
      "1. **Economic Policies**:\n",
      "   - **Tax Cuts and Jobs Act (2017)**: This legislation reduced the corporate tax rate from 35% to 21% and aimed to stimulate economic growth.\n",
      "   - **Deregulation**: Trump focused on reducing federal regulations, claiming it would benefit businesses and spur economic growth.\n",
      "\n",
      "2. **Trade Policies**:\n",
      "   - **Trade War with China**: Imposed tariffs on Chinese goods to address trade imbalances and intellectual property theft, leading to retaliatory tariffs from China.\n",
      "   - **USMCA**: Replaced NAFTA with the United States-Mexico-Canada Agreement, aiming to create a more balanced trade environment.\n",
      "\n",
      "3. **Immigration Policies**:\n",
      "   - **Border Security**: Advocated for building a wall along the U.S.-Mexico border to curb illegal immigration.\n",
      "   - **Travel Ban**: Implemented a travel ban on several predominantly Muslim countries, citing national security concerns.\n",
      "\n",
      "4. **Foreign Policy**:\n",
      "   - **\"America First\" Doctrine**: Prioritized American interests in foreign relations, often questioning long-standing alliances and agreements.\n",
      "   - **North Korea Diplomacy**: Engaged in unprecedented summits with North Korean leader Kim Jong-un to discuss denuclearization.\n",
      "\n",
      "5. **Healthcare**:\n",
      "   - **Attempts to Repeal Obamacare**: Made several attempts to repeal and replace the Affordable Care Act, though a full repeal was not achieved.\n",
      "\n",
      "6. **Judicial Appointments**:\n",
      "   - Appointed three Supreme Court justices (Neil Gorsuch, Brett Kavanaugh, and Amy Coney Barrett), significantly influencing the court's ideological balance.\n",
      "\n",
      "7. **COVID-19 Response**:\n",
      "   - Faced criticism for the handling of the COVID-19 pandemic, particularly regarding testing and public health messaging.\n",
      "\n",
      "8. **Social Issues**:\n",
      "   - **Criminal Justice Reform**: Signed the First Step Act, aimed at reforming sentencing laws and reducing recidivism.\n",
      "\n",
      "These actions reflect Trump's approach to governance, characterized by a focus on deregulation, nationalism, and a transactional view of international relations. His presidency was marked by significant controversy and polarization, influencing both domestic and global politics."
     ]
    }
   ],
   "source": [
    "# 문서 검색이 안되는 질문\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"도널드 트럼프 대통령\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "stream_graph(graph, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d0b46f",
   "metadata": {},
   "source": [
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
