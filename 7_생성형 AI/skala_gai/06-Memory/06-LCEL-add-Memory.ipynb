{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY Loading\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH06-Memory\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"CH06-Memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory with Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough, Runnable\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/37/2rwxb6k520l4tqxzpx1nh8lh0000gn/T/ipykernel_31628/4009527432.py:14: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(return_messages=True, memory_key='chat_history')\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의/초기화 \n",
    "model = ChatOpenAI()\n",
    "\n",
    "# 대화형 프롬프트 정의 \n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system','Your are a helpful assistant.'),\n",
    "        MessagesPlaceholder(variable_name='chat_history'),\n",
    "        ('human', '{input}'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 메모리 정의/초기화\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key='chat_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기화된 메모리 확인 \n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RunnableLambda : 괄호 내 함수 호출 \n",
    "# memory.load_memory_variables : 메모리에 대화 저장, 결과는 chat_history 변수에 저장 \n",
    "# itemgetter : chat_history 값을 리스트로 가져오도록 처리 \n",
    "runnable = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) \n",
    "    | itemgetter('chat_history')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Hello', 'chat_history': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runnable 결과 확인 \n",
    "runnable.invoke({'input':'Hello'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 정의\n",
    "chain = runnable | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 김영희님. 만나서 반가워요. 무엇을 도와드릴까요?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 대화 \n",
    "answer = chain.invoke({'input':'안녕하세요. 제 이름은 김영희 입니다. 만나서 반갑습니다.'})\n",
    "answer.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='안녕하세요. 제 이름은 김영희 입니다. 만나서 반갑습니다.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='안녕하세요, 김영희님. 만나서 반가워요. 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대화 내용을 메모리에 저장 \n",
    "memory.save_context(\n",
    "    {'human':'안녕하세요. 제 이름은 김영희 입니다. 만나서 반갑습니다.'},\n",
    "    {'ai':answer.content},\n",
    ")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'네, 김영희님이시죠. 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두번째 대화 \n",
    "answer = chain.invoke({'input':'제 이름 기억하세요?'})\n",
    "answer.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Conversation Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationChainClass(Runnable):\n",
    "\n",
    "    def __init__(self, llm, prompt, memory, input_key=\"input\"):\n",
    "\n",
    "        self.prompt = prompt\n",
    "        self.memory = memory\n",
    "        self.input_key = input_key\n",
    "\n",
    "        self.chain = (\n",
    "            RunnablePassthrough.assign(\n",
    "                chat_history=RunnableLambda(self.memory.load_memory_variables)\n",
    "                | itemgetter(memory.memory_key)  # memory_key 와 동일하게 입력\n",
    "            )\n",
    "            | prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    def invoke(self, query, configs=None, **kwargs):\n",
    "        answer = self.chain.invoke({self.input_key: query})\n",
    "        self.memory.save_context(inputs={\"human\": query}, outputs={\"ai\": answer})\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화 \n",
    "model = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name='gpt-4o-mini',\n",
    ")\n",
    "\n",
    "# 대화형 프롬프트 정의 \n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system','Your are a helpful assistant.'),\n",
    "        MessagesPlaceholder(variable_name='chat_history'),\n",
    "        ('human', '{input}'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 메모리 정의/초기화 \n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key='chat_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = ConversationChainClass(model, prompt, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 김영희님! 만나서 반갑습니다. 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke('안녕하세요. 제 이름은 김영희 입니다. 만나서 반갑습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'네, 김영희님! 당신의 이름을 기억하고 있습니다. 다른 질문이나 도움이 필요하신 것이 있으면 말씀해 주세요!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke('제 이름 기억하세요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'힘내세요, 김영희님! LCEL 문법 수업은 어려울 수 있지만, 그만큼 여러분의 실력이 쑥쑥 성장하는 과정이에요. 조금씩 나아지는 자신을 믿고, 포기하지 마세요! 모든 노력은 결국 좋은 결과로 돌아올 거예요. 화이팅! 😊'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke('오늘 LCEL 문법 수업 듣고 있는데 너무 힘들어요. 힘나는 멘트 주세요!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕하세요. 제 이름은 김영희 입니다. 만나서 반갑습니다.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요, 김영희님! 만나서 반갑습니다. 어떻게 도와드릴까요?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='제 이름 기억하세요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='네, 김영희님! 당신의 이름을 기억하고 있습니다. 다른 질문이나 도움이 필요하신 것이 있으면 말씀해 주세요!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='오늘 LCEL 문법 수업 듣고 있는데 너무 힘들어요. 힘나는 멘트 주세요!!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='힘내세요, 김영희님! LCEL 문법 수업은 어려울 수 있지만, 그만큼 여러분의 실력이 쑥쑥 성장하는 과정이에요. 조금씩 나아지는 자신을 믿고, 포기하지 마세요! 모든 노력은 결국 좋은 결과로 돌아올 거예요. 화이팅! 😊', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리 확인 \n",
    "conversation_chain.memory.load_memory_variables({})[\"chat_history\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
