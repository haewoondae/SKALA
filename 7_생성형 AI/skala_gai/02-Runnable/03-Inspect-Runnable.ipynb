{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY Loading\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH02-Runnable\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"CH02-Runnable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnable 구조 검토"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Store 생성\n",
    "vector_store = FAISS.from_texts(\n",
    "    [\n",
    "        \"영희는 스칼라 주식회사에서 근무하고 있습니다.\",\n",
    "        \"철수는 같은 회사에서 근무 하였습니다.\",\n",
    "        \"영희 직업은 개발자 입니다.\",\n",
    "        \"철수의 직업은 컨텐츠 기획자 입니다.\",\n",
    "    ],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "# Vector Store를 검색기로 사용\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# 템플릿 정의\n",
    "template = \"\"\"\n",
    "Answer the question based only on the following context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# Prompt 정의\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 모델 정의/초기화\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "# 문서 포맷 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "\n",
    "# Chain 구성\n",
    "retrieval_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그래프 구성 확인\n",
    "\n",
    "`chain.get_graph()` \n",
    "- 체인의 각 노드와 노드 간의 연결을 나타내는 그래프 객체 반환\n",
    "- Node : 체인의 각 단계\n",
    "- Edge : 단계 간의 데이터 흐름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프를 그리기 위한 라이브러리 설치\n",
    "# !pip install -qU grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4b083e49e9ae4ac597161f0750d82700': Node(id='4b083e49e9ae4ac597161f0750d82700', name='Parallel<context,question>Input', data=<class 'langchain_core.runnables.base.RunnableParallel<context,question>Input'>, metadata=None),\n",
       " '6ae2e26704cd4f358fd144c466a631cc': Node(id='6ae2e26704cd4f358fd144c466a631cc', name='Parallel<context,question>Output', data=<class 'langchain_core.utils.pydantic.RunnableParallel<context,question>Output'>, metadata=None),\n",
       " '71083ea7c4ac43d79b1ddaed76f3155e': Node(id='71083ea7c4ac43d79b1ddaed76f3155e', name='VectorStoreRetriever', data=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x11df09290>, search_kwargs={}), metadata=None),\n",
       " '969fbe7f2e9747779549777dd7a610b5': Node(id='969fbe7f2e9747779549777dd7a610b5', name='format_docs', data=RunnableLambda(format_docs), metadata=None),\n",
       " '06a46436ab8d45b1a33230b197c74f84': Node(id='06a46436ab8d45b1a33230b197c74f84', name='Passthrough', data=RunnablePassthrough(), metadata=None),\n",
       " '0a1974c5ed2347d3955f278e719ef011': Node(id='0a1974c5ed2347d3955f278e719ef011', name='PromptTemplate', data=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\nAnswer the question based only on the following context: {context}\\nQuestion: {question}\\n'), metadata=None),\n",
       " 'b3a422341c064f47b296adb5c1dff71e': Node(id='b3a422341c064f47b296adb5c1dff71e', name='ChatOpenAI', data=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11deec850>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11f94cb90>, root_client=<openai.OpenAI object at 0x11de64c50>, root_async_client=<openai.AsyncOpenAI object at 0x11f955510>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), metadata=None),\n",
       " '6e02ec86a66b4f2789b6694f98f06476': Node(id='6e02ec86a66b4f2789b6694f98f06476', name='StrOutputParser', data=StrOutputParser(), metadata=None),\n",
       " 'a03f9253eabf435eb780149b6af1ea10': Node(id='a03f9253eabf435eb780149b6af1ea10', name='StrOutputParserOutput', data=<class 'langchain_core.output_parsers.string.StrOutputParserOutput'>, metadata=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.get_graph().nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Edge(source='dc53538f6e85431fa42f64014611f63c', target='40766f0cb25e491488c3d3f28f1b5abf', data=None, conditional=False),\n",
       " Edge(source='04e21109430b4473bab6e92be87d6577', target='dc53538f6e85431fa42f64014611f63c', data=None, conditional=False),\n",
       " Edge(source='40766f0cb25e491488c3d3f28f1b5abf', target='d2e47cebe2324917a15bb6466a592773', data=None, conditional=False),\n",
       " Edge(source='04e21109430b4473bab6e92be87d6577', target='3d122ccf7c5a43cca7b7c7a08e87e5ab', data=None, conditional=False),\n",
       " Edge(source='3d122ccf7c5a43cca7b7c7a08e87e5ab', target='d2e47cebe2324917a15bb6466a592773', data=None, conditional=False),\n",
       " Edge(source='d2e47cebe2324917a15bb6466a592773', target='7e404e4b2ce4489194b773804c6b2438', data=None, conditional=False),\n",
       " Edge(source='7e404e4b2ce4489194b773804c6b2438', target='68ff55bbc2f94399b88cb9ff30c50833', data=None, conditional=False),\n",
       " Edge(source='9ed46daf135d472b9a81fecbb96886ff', target='8a3990fc21844ccdbb552db562f00700', data=None, conditional=False),\n",
       " Edge(source='68ff55bbc2f94399b88cb9ff30c50833', target='9ed46daf135d472b9a81fecbb96886ff', data=None, conditional=False)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.get_graph().edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그래프 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            +---------------------------------+          \n",
      "            | Parallel<context,question>Input |          \n",
      "            +---------------------------------+          \n",
      "                    ***               ***                \n",
      "                 ***                     ***             \n",
      "               **                           ***          \n",
      "+----------------------+                       **        \n",
      "| VectorStoreRetriever |                        *        \n",
      "+----------------------+                        *        \n",
      "            *                                   *        \n",
      "            *                                   *        \n",
      "            *                                   *        \n",
      "    +-------------+                     +-------------+  \n",
      "    | format_docs |                     | Passthrough |  \n",
      "    +-------------+*                    +-------------+  \n",
      "                    ***               ***                \n",
      "                       ***         ***                   \n",
      "                          **     **                      \n",
      "            +----------------------------------+         \n",
      "            | Parallel<context,question>Output |         \n",
      "            +----------------------------------+         \n",
      "                              *                          \n",
      "                              *                          \n",
      "                              *                          \n",
      "                     +----------------+                  \n",
      "                     | PromptTemplate |                  \n",
      "                     +----------------+                  \n",
      "                              *                          \n",
      "                              *                          \n",
      "                              *                          \n",
      "                       +------------+                    \n",
      "                       | ChatOpenAI |                    \n",
      "                       +------------+                    \n",
      "                              *                          \n",
      "                              *                          \n",
      "                              *                          \n",
      "                    +-----------------+                  \n",
      "                    | StrOutputParser |                  \n",
      "                    +-----------------+                  \n",
      "                              *                          \n",
      "                              *                          \n",
      "                              *                          \n",
      "                 +-----------------------+               \n",
      "                 | StrOutputParserOutput |               \n",
      "                 +-----------------------+               \n"
     ]
    }
   ],
   "source": [
    "retrieval_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프롬프트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\nAnswer the question based only on the following context: {context}\\nQuestion: {question}\\n')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.get_prompts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "* End of Document *"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
